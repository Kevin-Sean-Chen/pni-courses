{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEU502b Analysis: Signal Corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szoro/Documents/software/anaconda3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv, concat\n",
    "from scripts.utilities import read_gifti\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=1.5)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define metadata.\n",
    "func_dir = 'preproc/fmriprep'\n",
    "subjects = ['sub-01','sub-02']\n",
    "tasks = ['visualcontrol', 'visualbreathhold', 'visualhyperventilate']\n",
    "spaces = ['fsaverage5.L','fsaverage5.R']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Task Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from scripts.spm_hrf import spm_hrf\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Task metadata.\n",
    "n_acq = [250, 370, 370]\n",
    "tr = 1\n",
    "\n",
    "## Define upsampling level.\n",
    "sfreq = 100\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "## Generate HRF.\n",
    "hrf = spm_hrf(1/sfreq)\n",
    "\n",
    "for subj in subjects:\n",
    "    \n",
    "    for task, T in zip(tasks, n_acq):\n",
    "    \n",
    "         ## Prepare save-directory.\n",
    "        out_dir = os.path.join('first_levels', task)\n",
    "        if not os.path.isdir(out_dir): os.makedirs(out_dir)\n",
    "    \n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Load and prepare events.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        ## Load events file.\n",
    "        f = os.path.join('raw', subj, 'func', '%s_task-%s_events.tsv' %(subj,task))\n",
    "        events = read_csv(f, sep='\\t')\n",
    "\n",
    "        ## Drop fixation cross.\n",
    "        events = events[events.event == 'Checkerboard']\n",
    "\n",
    "        ## Round onset times.\n",
    "        events['onset'] = events['onset'].round(int(np.log10(sfreq)))\n",
    "\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Generate task regressors.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        ## Define TR onsets.\n",
    "        tr_onsets = np.arange(0, T, tr)\n",
    "        \n",
    "        ## Initialize boxcars.\n",
    "        times = np.linspace(0, T + 1/sfreq, T * sfreq).round(int(np.log10(sfreq)))\n",
    "        boxcars = np.zeros_like(times)\n",
    "\n",
    "        ## Generate boxcars.\n",
    "        for onset, duration in events[['onset','duration']].values:\n",
    "            ix = np.logical_and(times >= onset, times <= onset + duration)\n",
    "            boxcars[ix] += 1\n",
    "\n",
    "        ## Generate estimated hemodynamic response.\n",
    "        hemo = np.convolve(boxcars, hrf)[:times.size]\n",
    "\n",
    "        ## Downsample regressors.\n",
    "        boxcars = boxcars[np.in1d(times, tr_onsets)]\n",
    "        hemo = hemo[np.in1d(times, tr_onsets)]\n",
    "        times = times[np.in1d(times, tr_onsets)]\n",
    "\n",
    "        ## Scale estimated hemodynamic response.\n",
    "        hemo /= hemo.max()\n",
    "        \n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ### Save task regressors.\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "        ## Save.\n",
    "        f = os.path.join(out_dir, '%s_task-%s_events.txt' %(subj, task))\n",
    "        np.savetxt(f, hemo)\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: First Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from scripts.prewhitening import prewhiten_data\n",
    "from scripts.permutations import permutation_testing\n",
    "from scripts.utilities import mask_insert\n",
    "np.random.seed(47404)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Analysis parameters.\n",
    "n_perm = False \n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for task in tasks:\n",
    "    \n",
    "    ## Prepare save-directory.\n",
    "    out_dir = os.path.join('first_levels', task)\n",
    "    if not os.path.isdir(out_dir): os.makedirs(out_dir)\n",
    "    \n",
    "    for subj in subjects:\n",
    "\n",
    "        for space in spaces:\n",
    "\n",
    "            if not n_perm: break\n",
    "\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Load and prepare data.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Load task regressors.\n",
    "            f = os.path.join('first_levels',task,'%s_task-%s_events.txt' %(subj,task))\n",
    "            events = np.loadtxt(f)\n",
    "            if events.ndim == 1: events = events.reshape(-1,1)\n",
    "            _, n_task = events.shape\n",
    "\n",
    "            ## Load motion regressors.\n",
    "            f = os.path.join('first_levels',task,'%s_task-%s_motion.txt' %(subj,task))\n",
    "            motion = np.loadtxt(f)\n",
    "            if motion.ndim == 1: motion = motion.reshape(-1,1)\n",
    "                \n",
    "            ## Load task data.\n",
    "            f = os.path.join('first_levels',task,'%s_task-%s_space-%s.psc.npz' %(subj,task,space))\n",
    "            npz = np.load(f)\n",
    "\n",
    "            ## Remove null vertices. \n",
    "            data, mask = npz['psc'], npz['mask']\n",
    "            Y = data[:,mask]\n",
    "\n",
    "            ## Append intercept to nuisance regressors.\n",
    "            nuisance = np.concatenate([np.ones([motion.shape[0], 1]), motion], axis=-1)            \n",
    "            \n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Prewhiten data.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Construct design matrix.\n",
    "            X = np.concatenate([events, nuisance], axis=-1)\n",
    "\n",
    "            ## Prewhiten data (see script for details).\n",
    "            WY, WX = prewhiten_data(Y, X)\n",
    "\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### First-level regression.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Permutation testing (see script for details.)\n",
    "            B, F, p = permutation_testing(WY, WX, n_task, n_perm)\n",
    "\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Save results.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Save.\n",
    "            f = os.path.join(out_dir, '%s_task-%s_space-%s.ces.npz' %(subj, task, space))\n",
    "            np.savez_compressed(f, B=mask_insert(B,mask), F=mask_insert(F,mask), \n",
    "                                p=mask_insert(p,mask))\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Surface Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Significance threshold.\n",
    "alpha = 0.05\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "## Redefine threshold.\n",
    "threshold = -np.log10(alpha)\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    ## Define save-directory.\n",
    "    out_dir = os.path.join('first_levels', task)\n",
    "    \n",
    "    for subj in subjects:\n",
    "\n",
    "        for space in spaces:\n",
    "\n",
    "            ## Load data.\n",
    "            f = os.path.join(out_dir, '%s_task-%s_space-%s.ces.npz' %(subj, task, space))\n",
    "            npz = np.load(f)\n",
    "\n",
    "            ## Extract PSC and p-vals corresponding to checkerboard condition.\n",
    "            psc, pvals = npz['B'][0], npz['p'][0]\n",
    "\n",
    "            ## Threshold PSC by significance.\n",
    "            psc[np.abs(pvals) < threshold] = 0\n",
    "\n",
    "            ## Convert to NIFTI image.\n",
    "            obj = nib.Nifti1Image(psc.reshape(-1,1,1,1), np.identity(4))\n",
    "\n",
    "            ## Save.\n",
    "            f = os.path.join(out_dir, '%s_task-%s_space-%s.psc.nii.gz' %(subj, task, space))\n",
    "            nib.save(obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Effects of Corruption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize PSC in Visual Localizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import read_label\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define task.\n",
    "task = 'visualcontrol'\n",
    "\n",
    "## Define plotting style.\n",
    "sns.set(style=\"ticks\", context=\"paper\", font_scale=2)\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define paths.\n",
    "data_dir = 'first_levels/%s' %task\n",
    "label_dir = 'first_levels/labels'\n",
    "\n",
    "for i, subj in enumerate(subjects):\n",
    "    \n",
    "    ## Initialize canvas.\n",
    "    fig, ax = plt.subplots(1,1,figsize=(8,4))\n",
    "    colors = sns.color_palette(\"Paired\", n_colors=4).as_hex()\n",
    "    colors = np.array(colors).reshape(2,2)\n",
    "    \n",
    "    for j, space in enumerate(spaces):\n",
    "        \n",
    "        ## Load data.\n",
    "        f = os.path.join(data_dir, '%s_task-%s_space-%s.psc.npz' %(subj, task, space))\n",
    "        data = np.load(f)['psc']\n",
    "        \n",
    "        ## Load contrast.\n",
    "        f = os.path.join(data_dir, '%s_task-%s_space-%s.psc.nii.gz' %(subj, task, space))\n",
    "        psc = nib.load(f).get_data()\n",
    "        \n",
    "        ## Load label.\n",
    "        hemi = 'lh' if space == 'fsaverage5.L' else 'rh'\n",
    "        f = os.path.join(label_dir, '%s_V1-%s.label' %(subj, hemi))\n",
    "        label = read_label(f)\n",
    "        \n",
    "        ## Mask data by label.\n",
    "        data = data[:,label.vertices].mean(axis=-1)\n",
    "        psc = psc[label.vertices]\n",
    "        \n",
    "        ## Plot.\n",
    "        ax.plot(data, lw=5, label=hemi, color=colors[i,j], alpha=0.95)\n",
    "        \n",
    "    ## Add info.\n",
    "    for tmin, tmax in zip(np.arange(10,250,40), np.arange(30,250,40)):\n",
    "        ax.fill_between(np.arange(tmin,tmax), -3.5, 3.5, color='0.4')\n",
    "    ax.set(xlim=(-0.5, 250.5), xlabel='Time (s)', ylim=(-3.5,3.5), \n",
    "           yticks=[-3,0,3], ylabel='Percent Signal Change')\n",
    "    ax.legend(loc=1, ncol=2, borderpad=-0.5, handletextpad=0.4,\n",
    "              columnspacing=0.4, handlelength=1.5)\n",
    "\n",
    "    ## Save figure.\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/fig1/%s_V1_psc.png' %subj, dpi=180)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast PSC across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szoro/Documents/software/anaconda3.6/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/media/szoro/SZORO1/pni-courses/neu502b/fmri/scripts/prewhitening.py:28: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  B_ols, _, _, _ = np.linalg.lstsq(X, Y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01 visualcontrol fsaverage5.L 3.11 (0.33)\n",
      "sub-01 visualcontrol fsaverage5.R 3.13 (0.35)\n",
      "sub-01 visualbreathhold fsaverage5.L 3.13 (0.38)\n",
      "sub-01 visualbreathhold fsaverage5.R 2.98 (0.36)\n",
      "sub-01 visualhyperventilate fsaverage5.L 1.53 (0.17)\n",
      "sub-01 visualhyperventilate fsaverage5.R 1.41 (0.16)\n",
      "sub-01 Con vs. Breath: 0.04 (0.848)\n",
      "sub-01 Con vs. Hyper: 38.19 (0.000)\n",
      "sub-02 visualcontrol fsaverage5.L 1.67 (0.27)\n",
      "sub-02 visualcontrol fsaverage5.R 1.70 (0.23)\n",
      "sub-02 visualbreathhold fsaverage5.L 0.54 (0.23)\n",
      "sub-02 visualbreathhold fsaverage5.R 0.41 (0.24)\n",
      "sub-02 visualhyperventilate fsaverage5.L 0.44 (0.14)\n",
      "sub-02 visualhyperventilate fsaverage5.R 1.05 (0.14)\n",
      "sub-02 Con vs. Breath: 24.45 (0.000)\n",
      "sub-02 Con vs. Hyper: 20.94 (0.000)\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from scipy.linalg import block_diag\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Preallocate space.\n",
    "info = []\n",
    "\n",
    "for subj in subjects:\n",
    "    \n",
    "    WX, WY = [], []\n",
    "    \n",
    "    for task in tasks:\n",
    "        \n",
    "        ## Prepare save-directory.\n",
    "        out_dir = os.path.join('first_levels', task)\n",
    "        if not os.path.isdir(out_dir): os.makedirs(out_dir)\n",
    "\n",
    "        for space in spaces:\n",
    "\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Load and prepare data.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Load task regressors.\n",
    "            f = os.path.join('first_levels',task,'%s_task-%s_events.txt' %(subj,task))\n",
    "            events = np.loadtxt(f)\n",
    "            if events.ndim == 1: events = events.reshape(-1,1)\n",
    "            _, n_task = events.shape\n",
    "\n",
    "            ## Load motion regressors.\n",
    "            f = os.path.join('first_levels',task,'%s_task-%s_motion.txt' %(subj,task))\n",
    "            motion = np.loadtxt(f)\n",
    "            if motion.ndim == 1: motion = motion.reshape(-1,1)\n",
    "                \n",
    "            ## Load task data.\n",
    "            f = os.path.join('first_levels',task,'%s_task-%s_space-%s.psc.npz' %(subj,task,space))\n",
    "            npz = np.load(f)\n",
    "\n",
    "            ## Load label.\n",
    "            hemi = 'lh' if space == 'fsaverage5.L' else 'rh'\n",
    "            f = os.path.join(label_dir, '%s_V1-%s.label' %(subj, hemi))\n",
    "            label = read_label(f)\n",
    "\n",
    "            ## Mask data by label.\n",
    "            y = npz['psc'][:,label.vertices].mean(axis=-1).reshape(-1,1)\n",
    "\n",
    "            ## Append intercept to nuisance regressors.\n",
    "            nuisance = np.concatenate([np.ones([motion.shape[0], 1]), motion], axis=-1)            \n",
    "            \n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "            ### Prewhiten data.\n",
    "            #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "            ## Construct design matrix.\n",
    "            X = np.concatenate([events, nuisance], axis=-1)\n",
    "\n",
    "            ## Prewhiten data (see script for details).\n",
    "            wy, wX = prewhiten_data(y, X)\n",
    "            wX, wy = wX.squeeze(), wy.squeeze()\n",
    "            \n",
    "            ## Append.\n",
    "            WX.append(wX)\n",
    "            WY.append(wy)\n",
    "                        \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### First level regression.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Identify checkerboard contrast.\n",
    "    indices = np.insert(np.cumsum([wx.shape[-1] for wx in WX])[:-1], 0, 0)\n",
    "\n",
    "    ## Perform OLS.\n",
    "    WX = block_diag(*WX)\n",
    "    WY = np.concatenate(WY)\n",
    "    fit = OLS(WY, WX).fit()\n",
    "    \n",
    "    ## Iteratively print info.\n",
    "    b = fit.params[indices].reshape(3,2)\n",
    "    t = fit.tvalues[indices].reshape(3,2)\n",
    "    for i, task in enumerate(tasks):\n",
    "        for j, space in enumerate(spaces):\n",
    "            info.append([subj,task,space,b[i,j],(b/t)[i,j]])\n",
    "            print('%s %s %s %0.2f (%0.2f)' %(subj,task,space,b[i,j],(b/t)[i,j]))\n",
    "\n",
    "    ## Perform contrasts (Control vs. Breathhold).\n",
    "    contrast = [1,1,-1,-1,0,0]\n",
    "    r_matrix = np.zeros_like(fit.params)\n",
    "    r_matrix[indices] = contrast\n",
    "    f_test = fit.f_test(r_matrix)\n",
    "    print('%s Con vs. Breath: %0.2f (%0.3f)' %(subj, f_test.fvalue, f_test.pvalue))\n",
    "\n",
    "    ## Perform contrasts (Control vs. Hyperventilate).\n",
    "    contrast = [1,1,0,0,-1,-1]\n",
    "    r_matrix = np.zeros_like(fit.params)\n",
    "    r_matrix[indices] = contrast\n",
    "    f_test = fit.f_test(r_matrix)\n",
    "    print('%s Con vs. Hyper: %0.2f (%0.3f)' %(subj, f_test.fvalue, f_test.pvalue))\n",
    "    \n",
    "## Dump info to file.\n",
    "info = DataFrame(info, columns=('Subject','Task','Space','PSC','se'))\n",
    "info.to_csv('first_levels/corrupted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
