{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness of Crayfish Nervous System to Environmental pH\n",
    "## Step 1: Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import neo, os\n",
    "import numpy as np\n",
    "from mne import create_info\n",
    "from mne.io import RawArray\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "files = [f for f in os.listdir('raw') if f.endswith('abf')]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main body.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "for f in files:\n",
    "\n",
    "    ## Load recordings.\n",
    "    recordings, = neo.AxonIO(filename='raw/%s' %f).read_block().segments\n",
    "    signal, = recordings.analogsignals\n",
    "\n",
    "    ## Concatenate raw recordings.\n",
    "    data = np.hstack([np.asarray(signal, dtype=np.float64)  * 1e-6]).T\n",
    "\n",
    "    ## Create info object.\n",
    "    sfreq = float(signal.sampling_rate)\n",
    "    ch_names = ['nerve']\n",
    "    ch_types = 'bio'\n",
    "\n",
    "    info = create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "    ## Create Raw object.\n",
    "    raw = RawArray(data, info, verbose=False)\n",
    "\n",
    "    ## Save Raw object.  \n",
    "    raw.save('raw/%s' %f.replace('.abf','_raw.fif'), overwrite=True, verbose=False)\n",
    "    \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from mne.io import Raw\n",
    "from pandas import DataFrame\n",
    "from spike_sorting import *\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=2)\n",
    "%matplotlib inline\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "files = [f for f in os.listdir('raw') if f.endswith('fif')]\n",
    "\n",
    "## Filter parameters.\n",
    "l_freq = 300\n",
    "h_freq = 3000\n",
    "\n",
    "## Spike sorting parameters.\n",
    "k = 5\n",
    "reject = 200 # uV\n",
    "\n",
    "## Resampling.\n",
    "rule = '0.5S' # 500 ms\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "np.random.seed(47404)\n",
    "\n",
    "for f in files:\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Load and prepare data.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Load raw.\n",
    "    raw = Raw('raw/%s' %f, preload=True, verbose=False)\n",
    "\n",
    "    ## Filter data.\n",
    "    raw = raw.filter(l_freq, h_freq, picks=[0], method='fir', phase='zero', fir_design='firwin', verbose=False)\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Spike sorting.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Extract data.\n",
    "    data, times = raw.get_data(return_times=True)\n",
    "    data = data.squeeze() * 1e6\n",
    "        \n",
    "    ## Find peaks.\n",
    "    threshold = find_threshold(data, k)\n",
    "    peak_loc, peak_mag = peak_finder(data, threshold)\n",
    "    peak_loc = raw.times[peak_loc]\n",
    "    \n",
    "    ## Amplitude rejection.\n",
    "    peak_loc = peak_loc[peak_mag < reject]\n",
    "    peak_mag = peak_mag[peak_mag < reject]\n",
    "    \n",
    "    ## Determine optimal number of clusters with gap statistic.\n",
    "    gap = gap_statistic(peak_mag.reshape(-1, 1), n_clusters=3, n_ref=10)\n",
    "    n_clusters = np.argmax(gap) + 1\n",
    "    \n",
    "    ## Spike clustering.\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=47404)\n",
    "    fit = km.fit(peak_mag.reshape(-1, 1))\n",
    "    clusters = fit.predict(peak_mag.reshape(-1, 1))\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Assemble into DataFrame.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    ## Initialize DataFrame.\n",
    "    df = DataFrame(np.vstack([clusters, peak_loc, peak_mag]).T, columns=('Cluster','Time','Amplitude'))\n",
    "    df.index = df.Time.apply(seconds_to_timeindex)\n",
    "    \n",
    "    ## Re-sort cluster index by mean amplitude in descending order.\n",
    "    order = np.argsort( df.groupby('Cluster').Amplitude.mean().as_matrix() )\n",
    "    order = np.max(order) - order\n",
    "    df.Cluster = order[df.Cluster.astype(int)]\n",
    "\n",
    "    ## Compute ISI (separated by cluster).\n",
    "    df['ISI'] = False\n",
    "    for cluster in df.Cluster.unique():\n",
    "        df.loc[df.Cluster==cluster,'ISI'] = np.insert( np.diff(df.loc[df.Cluster==cluster, 'Time']), 0, np.nan )\n",
    "    df['ISI'] = df['ISI'].astype(float)\n",
    "    \n",
    "    ## Save data.\n",
    "    df.to_csv('proc/%s' %f.replace('_raw.fif', '.csv'), index=False)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Quality check plots.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Initialize canvas.\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "\n",
    "    ## Plot timeseries samples.\n",
    "    gs = gridspec.GridSpec(1, 3)\n",
    "    gs.update(left=0.075, right=0.70, bottom=0.785,  top=0.98, wspace=0.02)\n",
    "\n",
    "    xlims = [(0.1,1.1), (times.mean()-0.5, times.mean()+0.5), (times.max()-1, times.max())]\n",
    "    xlabels = ['First 1s', 'Middle 1s', 'Final 1s']\n",
    "\n",
    "    for i, xlim, xlabel in zip(range(3),xlims,xlabels):\n",
    "\n",
    "        ## Initialize axis. Define indices.\n",
    "        ax = plt.subplot(gs[i])\n",
    "        ix1 = np.logical_and(times >= xlim[0], times <= xlim[1])\n",
    "        ix2 = np.logical_and(peak_loc >= xlim[0], peak_loc <= xlim[1])\n",
    "\n",
    "        ## Plot spikes.\n",
    "        plot_spikes(times[ix1], data[ix1], df.Time[ix2], clusters=df.Cluster[ix2],\n",
    "                    threshold=threshold, ax=ax) \n",
    "\n",
    "        ## Add info.\n",
    "        ax.set(xlim=xlim, xticks=[], xlabel=xlabel, ylim=(-50,75), yticks=[])\n",
    "        if not i: ax.set(yticks=np.arange(-50,80,25), ylabel=r'Amplitude ($\\mu V$)')\n",
    "\n",
    "    ## Plot timeseries of spike counts.\n",
    "    gs = gridspec.GridSpec(3, 1)\n",
    "    gs.update(left=0.075, right=0.70, bottom=0.05,  top=0.74, wspace=0, hspace=0.25)\n",
    "\n",
    "    ax = plt.subplot(gs[0])\n",
    "    for cluster in df.Cluster.unique():\n",
    "        resample = df.loc[df.Cluster==cluster,'Amplitude'].resample(rule).count()\n",
    "        ax.plot(timeindex_to_seconds(resample.index), resample.as_matrix()*2)\n",
    "    ax.set(xlim=(times.min(), times.max()), xlabel='Time (s)', ylabel=r'Frequency (Hz)')\n",
    "\n",
    "    ## Plot timeseries of magnitudes.\n",
    "    ax = plt.subplot(gs[1])\n",
    "    for cluster in df.Cluster.unique():\n",
    "        resample = df.loc[df.Cluster==cluster,'Amplitude'].resample(rule).mean()\n",
    "        ax.plot(timeindex_to_seconds(resample.index), resample.as_matrix())\n",
    "    ax.set(xlim=(times.min(), times.max()), xlabel='Time (s)', ylabel=r'Amplitude ($\\mu V$)')\n",
    "\n",
    "    ## Plot timeseries of ISI.\n",
    "    ax = plt.subplot(gs[2])\n",
    "    for cluster in df.Cluster.unique():\n",
    "        resample = df.loc[df.Cluster==cluster,'ISI'].resample(rule).mean()\n",
    "        ax.plot(timeindex_to_seconds(resample.index), resample.as_matrix())\n",
    "    ax.set(xlim=(times.min(), times.max()), xlabel='Time (s)', ylabel=r'ISI (s)')\n",
    "\n",
    "    ## Plot gap statistics.\n",
    "    gs = gridspec.GridSpec(4, 1)\n",
    "    gs.update(left=0.775, right=0.98, bottom=0.05,  top=0.98, wspace=0, hspace=0.25)\n",
    "\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.barplot(np.arange(3)+1,gap, palette=sns.cubehelix_palette(n_colors=3), ax=ax)\n",
    "    ax.set(xticklabels=[r'$K=1$',r'$K=2$',r'$K=3$'], ylabel='Gap Statistic')\n",
    "\n",
    "    ## Plot spike counts.\n",
    "    ax = plt.subplot(gs[1])\n",
    "    sns.countplot(x='Cluster', data=df, ax=ax)\n",
    "    ax.set(xticklabels=[r'%0.0f $\\mu V$' %a for a in df.groupby('Cluster').Amplitude.mean()], ylabel='Frequency')\n",
    "\n",
    "    ## Plot histogram of spike magnitudes.\n",
    "    ax = plt.subplot(gs[2])\n",
    "    for cluster in df.Cluster.unique():\n",
    "        arr = df.loc[df.Cluster==cluster,'Amplitude']\n",
    "        sns.distplot(arr, hist=False, kde=True, kde_kws=dict(lw=2.5,alpha=0.7))\n",
    "    ax.set(xlim=(0,100), xticks=[0,50,100], xlabel=r'Amplitude ($\\mu$V)', ylabel='Density')\n",
    "\n",
    "    ## Plot histogram of spike magnitudes.\n",
    "    ax = plt.subplot(gs[3])\n",
    "    for cluster in df.Cluster.unique():\n",
    "        arr = df.loc[df.Cluster==cluster,'ISI'].dropna().astype(float)\n",
    "        sns.distplot(arr, hist=False, kde=True, kde_kws=dict(lw=2.5,alpha=0.7))\n",
    "    ax.set(xlim=(-0.05,1.05), xticks=[0,0.5,1], xlabel=r'ISI (s)', ylabel='Density')\n",
    "\n",
    "    sns.despine()\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, wspace=0.2)\n",
    "    plt.savefig('qc/%s' %f.replace('_raw.fif', '.png'), dpi=150)\n",
    "    plt.close('all')\n",
    "    \n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
